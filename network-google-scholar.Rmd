# Getting data from [Web of Science](https://www.webofscience.com/wos/woscc/basic-search)

I searched all papers with "phylogenetic networks" in title or abstract (see query link [here](https://www.webofscience.com/wos/woscc/summary/c754b716-2ce8-47af-a298-5e16fefa7230-ef16f729/relevance/1)).

There are 7288 records, but you cannot download them all at the same time, so I have to download as excel 1000 at a time.
 
Raw datafiles in folder `data`:
- `savedrecs.xls`
- `savedrecs (1).xls`
- `savedrecs (2).xls`
- `savedrecs (3).xls`
- `savedrecs (4).xls`
- `savedrecs (5).xls`
- `savedrecs (6).xls`
- `savedrecs (7).xls`
 
which I renamed to remove spaces and parenthesis as:
- `savedrecs.xls`
- `savedrecs1.xls`
- `savedrecs2.xls`
- `savedrecs3.xls`
- `savedrecs4.xls`
- `savedrecs5.xls`
- `savedrecs6.xls`
- `savedrecs7.xls`

Sadly, we need to manually save as tab separated files (not csv bc commas separate author names) because you get an error if trying to open directly in R.

Not that we have to do other manual work. Since it is a tab separated file, we use `sep='\t'` to read it, but if the file as an actual `\t` in the text, it will break. So, we need to replace all `\t` with `x`.

Actually, now that we are doing manual work, we might as well delete unnecessary columns. We will keep:
- article title
- source title (journal)
- times cited (all databases)
- publication year

I should have kept the raw files, but I saved in place, and then saved as csv:
- `savedrecs.csv`
- `savedrecs1.csv`
- `savedrecs2.csv`
- `savedrecs3.csv`
- `savedrecs4.csv`
- `savedrecs5.csv`
- `savedrecs6.csv`
- `savedrecs7.csv`



## Read all the datafiles

```{r}
d = read.csv("data/savedrecs.csv", header=TRUE)
d1 = read.csv("data/savedrecs1.csv", header=TRUE)
d2 = read.csv("data/savedrecs2.csv", header=TRUE)
d3 = read.csv("data/savedrecs3.csv", header=TRUE)
d4 = read.csv("data/savedrecs4.csv", header=TRUE)
d5 = read.csv("data/savedrecs5.csv", header=TRUE)
d6 = read.csv("data/savedrecs6.csv", header=TRUE)
d7 = read.csv("data/savedrecs7.csv", header=TRUE)

df <- rbind(d,d1,d2,d3,d4,d5,d6,d7)
head(df)
str(df)
```
## Getting counts of papers per year

```{r}
df.counts = as.data.frame(table(df$Publication.Year))
str(df.counts)

df.counts2 <- within(df.counts, Var1 <- as.numeric(as.character(Var1)))
str(df.counts2)
```

We want to remove everything before 1994:
```{r}
df.c = df.counts2[df.counts2$Var1>1993,]
```

## Plotting the number of publications

```{r}
library(ggplot2)
library(viridis)
library(wesanderson)
pal <- wes_palette("Royal2", 10, type = "continuous")
#pal <- wes_palette("Darjeeling2", 10, type = "continuous")
#pal <- wes_palette("Chevalier1", 10, type = "continuous")
#pal <- wes_palette("Moonrise2", 10, type = "continuous")

pdf("publications.pdf",width=10,height=10)
ggplot(df.c,aes(x=Var1,y=Freq, fill=Var1))+geom_bar(stat="identity")+
#ggplot(df.c,aes(x=Var1,y=Freq, fill=Freq))+geom_bar(stat="identity")+
  xlab("")+ylab("")+
  scale_x_continuous(breaks = seq(1994, 2024, by = 1))+
  theme(
          axis.text.x = element_text(colour="grey", size=rel(2.0), angle=90, hjust=.5, vjust=.5, face="plain"),
          axis.text.y = element_text(colour="grey", size=rel(2.0), hjust=.5, vjust=.5, face="plain"),
          axis.ticks.x = element_blank(),
          panel.background = element_rect(fill = NA, color = "grey"),
          axis.line = element_line(colour = "grey"),
          strip.text = element_text(size = rel(1.5)),
          legend.position = "none"
        )+
  scale_fill_gradientn(colours = pal)
  #scale_fill_viridis(direction=-1)
  #scale_fill_viridis(option="magma", direction=-1)
dev.off()
```

## Focusing on both year and journal
```{r}
df.counts3 = as.data.frame(table(df$Publication.Year, df$Source.Title))
```

# Future work

We originally wanted to do this for "abba-baba" and combination of citations of snaq+phylonet, but we won't do that because we do not need that many statistics, I think.